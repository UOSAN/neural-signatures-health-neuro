---
title: "Prep FV Partial Validation Sample Data"
author: "Dani Cosme"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    df_print: paged
    highlight: tango
    theme: united
    toc: yes
    toc_float:
      collapsed: yes
      smooth_scroll: yes
  pdf_document:
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
options(scipen = 999)
```

# load packages
```{r}
library(tidyverse)
```

# load task files
```{r}
file_dir = "~/Documents/code/sanlab/CHIVES_scripts/fMRI/mvpa/taskInfo/"
file_pattern = "taskData_CHIVES[0-9]{4}.csv"
file_list = list.files(file_dir, pattern = file_pattern)

task = data.frame()

for (file in file_list) {
  temp = tryCatch(read.csv(paste0(file_dir,file), header = FALSE) %>%
                    rename("health" = V1,
                           "trial" = V2,
                           "bid" = V3,
                           "rt" = V4) %>%
                    mutate(file = file) %>%
                    extract(file,"subjectID","taskData_(CHIVES[0-9]{4}).csv") %>%
                    mutate(health = ifelse(health == 0, "healthy",
                                    ifelse(health == 1, "unhealthy", NA))), error = function(e) message(file))
  task = rbind(task, temp)
  rm(temp)
}

task = task %>%
  mutate_if(is.numeric, funs(ifelse(. == "NaN", NA, .)))
```

# load striping info
```{r}
striping = read.csv("striping_QC_partial.csv")
```

# load mean intensity values
```{r}
file_dir = "dotProducts_partial_validation/"
file_pattern = "CHIVES1[0-9]{3}_meanIntensity.txt"
file_list = list.files(file_dir, pattern = file_pattern)

intensities = data.frame()

for (file in file_list) {
  temp = tryCatch(read.table(file.path(file_dir,file), fill = TRUE) %>%
                    rename("subjectID" = V1,
                           "meanIntensity" = V3) %>%
                    extract(V2, "beta", "beta_([0-9]{4}).nii") %>%
                    mutate(beta = as.integer(beta)), error = function(e) message(file))
  intensities = rbind(intensities, temp)
  rm(temp)
}
```

# load dot products
```{r}
file_dir = "dotProducts_partial_validation/"
file_pattern = "CHIVES[0-9]{4}_dotProducts.txt"
file_list = list.files(file_dir, pattern = file_pattern)

dots = data.frame()

for (file in file_list) {
  temp = tryCatch(read.table(file.path(file_dir,file), fill = TRUE) %>%
                    rename("subjectID" = V1,
                           "map" = V3,
                           "dotProduct" = V4) %>%
                    extract(V2, "beta", "beta_([0-9]{4}).nii") %>%
                    extract(map, "algorithm", "(.*)_.*.nii") %>%
                    mutate(beta = as.integer(beta)), error = function(e) message(file))
  dots = rbind(dots, temp)
  rm(temp)
}
```

# join intensities and dots
* recode trials with extreme intensities as NA
```{r}
dots.merged = dots %>%
  left_join(., intensities, by = c("subjectID", "beta")) %>%
  group_by(subjectID, algorithm) %>%
  mutate(rownum = row_number())

# plot original
dots.merged %>%
  filter(algorithm == "logistic") %>%
  ggplot(aes(1, meanIntensity)) +
    geom_boxplot()

# assess extreme values and exclude when calculating SDs
dots.merged %>%
  filter(algorithm == "logistic") %>%
  arrange(meanIntensity)

dots.merged %>%
  filter(algorithm == "logistic") %>%
  arrange(-meanIntensity)

# recode outliers as NA
dots.merged = dots.merged %>%
  ungroup() %>%
  mutate(meanIntensity = ifelse(meanIntensity > 1 | meanIntensity < -1, NA, meanIntensity),
         median = median(meanIntensity, na.rm = TRUE),
         sd3 = 3*sd(meanIntensity, na.rm = TRUE),
         outlier = ifelse(meanIntensity > median + sd3 | meanIntensity < median - sd3, "yes", "no"),
         dotProduct = ifelse(outlier == "yes", NA, dotProduct))
  
# plot after
dots.merged %>%
  filter(algorithm == "logistic") %>%
  filter(outlier == "no") %>%
  ggplot(aes(1, meanIntensity)) +
    geom_boxplot()
```

# exclude outliers and standardize
* standardize within algorithm and contrast
```{r}
dots.ex = dots.merged %>%
  group_by(algorithm, subjectID) %>%
  mutate(trial = row_number()) %>%
  left_join(., striping, by = c("subjectID", "beta"))  %>%
  mutate(dotProduct = ifelse(!is.na(striping), NA, dotProduct)) %>%
  filter(!algorithm %in% c("ridge", "svm")) %>%
  group_by(subjectID, algorithm) %>% # standardize within sub and algorithm
  mutate(dotSTD = scale(dotProduct, center = FALSE))
```

# summarize trials
```{r}
dots.ex %>%
  filter(algorithm == "logistic") %>%
  group_by(subjectID) %>%
  summarize(n = n()) %>%
  arrange(n)
```

# merge data
Exclusions

* Motion exclusions (>10%): CHIVES1095
* Technical failure: CHIVES1082
* Incidental finding: CHIVES1070

```{r}
data = left_join(dots.ex, task, by = c("subjectID", "trial")) %>%
  filter(!subjectID %in% c("CHIVES1095", "CHIVES1082", "CHIVES1070")) %>%
  ungroup() %>%
  mutate(algorithm = ifelse(algorithm == "reg_look", "regulate > look", 
                     ifelse(algorithm == "reg", "regulate > rest", 
                     ifelse(algorithm == "logistic", "logistic classifier", algorithm))))
```

# save variables
```{r}
saveRDS(data, "FV_partial_validation.RDS")
```
